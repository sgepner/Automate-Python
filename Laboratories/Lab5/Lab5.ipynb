{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87311733",
   "metadata": {},
   "source": [
    "## Lab 5\n",
    "\n",
    "In this lab we will using python for image processing using Computer vision library. As you might have already seen that computer vision based technologies for to mechanical/aerospace problems such Autnomous Maneurs/Control. These technologies are based on image based operations and generally working on huge data sets. Feature extractions or data processing needs to performed on these data sets.\n",
    "\n",
    "\n",
    "Based on paradigm of introduced in Lecture 5 i.e Serialization of data and use of external application API, We will be extracting the features of images for feeding to the Machine learningn API for making predictions. In this lab we will only perfrom tasks related to feature extraction.\n",
    "\n",
    "Our data sets consitute of flow simulation snapshots at regular time steps. We have some flow simulation images and we wil create functions to crop the images by triminng the extra part.  Second we have to create a function for extracting the edges in the imgaes. Which in our case will shows the boundary of wake. So using the python we will caculating the wake size for that you need to write a function for curve integration.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a21c831",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Folder **pics** contains images, image names cotains Reynolds number and time. Create a class with relevants attribute for extracting and storing the Reynolds number, time and name of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec58b78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c16d8256",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Crop the images for removing the extra part other than the flow domain. Store all the cropped images in the details. As you know, the images are just a matrix. So you need to extend your class for storing the matrix. Store only the black and white channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994d5242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(902, 2072, 3)\n",
      "[[[  0 182 200]\n",
      "  [  0 182 200]\n",
      "  [  0 182 200]\n",
      "  ...\n",
      "  [  0 182 200]\n",
      "  [  0 182 200]\n",
      "  [  0 182 200]]\n",
      "\n",
      " [[  0 182 200]\n",
      "  [  0 182 200]\n",
      "  [  0 182 200]\n",
      "  ...\n",
      "  [  0 182 200]\n",
      "  [  0 182 200]\n",
      "  [  0 182 200]]\n",
      "\n",
      " [[  0 182 200]\n",
      "  [  0 182 200]\n",
      "  [  0 182 200]\n",
      "  ...\n",
      "  [  0 182 200]\n",
      "  [  0 182 200]\n",
      "  [  0 182 200]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[110  87  82]\n",
      "  [110  87  82]\n",
      "  [110  87  82]\n",
      "  ...\n",
      "  [110  87  82]\n",
      "  [110  87  82]\n",
      "  [110  87  82]]\n",
      "\n",
      " [[110  87  82]\n",
      "  [110  87  82]\n",
      "  [110  87  82]\n",
      "  ...\n",
      "  [110  87  82]\n",
      "  [110  87  82]\n",
      "  [110  87  82]]\n",
      "\n",
      " [[110  87  82]\n",
      "  [110  87  82]\n",
      "  [110  87  82]\n",
      "  ...\n",
      "  [110  87  82]\n",
      "  [110  87  82]\n",
      "  [110  87  82]]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread('d:\\courses\\SG\\Automate-Python\\Laboratories\\Lab5\\pics\\\\Re_140_t_0000.png')\n",
    "print(img.shape) # Print image shape\n",
    "cv2.imshow(\"original\", img)\n",
    " \n",
    "# Cropping an image\n",
    "cropped_image = img[350:680, 650:1230]\n",
    " \n",
    "# Display cropped image\n",
    "cv2.imshow(\"cropped\", cropped_image)\n",
    " \n",
    "# Save the cropped image\n",
    "\n",
    "cv2.imwrite(\"Cropped Image.jpg\", cropped_image)\n",
    " \n",
    "# print the image matrix\n",
    "print(cropped_image)\n",
    "\n",
    " \n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Gray scale of Cropped image\n",
    "cv2.imshow(\"cropped\", gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8802819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place for solution for task 2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "354e9133",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Now retrieve the data of cropped images for extracting the edges of the boundary. Below are code snippets for edge extraction of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28323c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hope you have already working python computer vision which you can check by importing it. \n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread'd:\\courses\\SG\\Automate-Python\\Laboratories\\Lab5\\pics\\\\Re_140_t_0000.png')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur to reduce noise\n",
    "blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "# Apply Canny edge detection algorithm with threshold values of 100 and 200\n",
    "edges = cv2.Canny(blur, 100, 200)\n",
    "\n",
    "# Display the original image and the edge detection result\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0cdf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place for solution ofr task 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e1e6945",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "Now create a function for measuring the intensity of wake in the flow field. For that you need to integrate the edges obtained from the previous function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947fc8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
